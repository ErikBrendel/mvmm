{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "%matplotlib inline\n",
    "%run LocalRepo.ipynb\n",
    "%run repos.ipynb\n",
    "%run parsing.ipynb\n",
    "%run metrics.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pattern_match(coupling_values, pattern, support_values):\n",
    "    \"\"\"how good does this node-pair fit to the given pattern? Range: [0, 1]\"\"\"\n",
    "    error_sum = 0; values = 0; support = 1\n",
    "    for i, coupling_val in enumerate(coupling_values):\n",
    "        if pattern[i] is not None:\n",
    "            error = abs(pattern[i] - coupling_val)\n",
    "            error_sum += error * error\n",
    "            values += 1\n",
    "            support = min(support, support_values[i])\n",
    "    match_score = 1. - (error_sum / values)\n",
    "    return match_score, support\n",
    "\n",
    "\n",
    "# as seen in:\n",
    "# https://thelaziestprogrammer.com/python/a-multiprocessing-pool-pickle\n",
    "# https://thelaziestprogrammer.com/python/multiprocessing-pool-a-global-solution\n",
    "class StaticStuff:\n",
    "    analysis_graphs = None\n",
    "    target_patterns = None\n",
    "\n",
    "MIN_PATTERN_MATCH = 0  # how close the coupling values need to match the pattern to be a result\n",
    "MIN_SUPPORT = 0  # how much relative support a result needs to not be discarded\n",
    "def analyze_pair(pair): #, analysis_graphs, target_patterns):\n",
    "    # pdb.set_trace()\n",
    "    _a, _b = pair\n",
    "    if _a.startswith(_b) or _b.startswith(_a):  # ignore nodes that are in a parent-child relation\n",
    "        return None\n",
    "    # for each view: how much support do we have for this node pair (minimum of both node support values)\n",
    "    support_values = [min(supp_a, supp_b) for supp_a, supp_b in zip(*[\n",
    "        [g.get_normalized_support(node) for g in StaticStuff.analysis_graphs] for node in [_a, _b]\n",
    "    ])]\n",
    "    result = [[] for p in StaticStuff.target_patterns]\n",
    "    for a, b in [(_a, _b), (_b, _a)]:\n",
    "        if (a,b) == (\"logic/Background.java/Background/stars0\", \"logic/Background.java/Background/background\"):\n",
    "            pdb.set_trace()\n",
    "        normalized_coupling_values = tuple([g.get_normalized_coupling(a, b) for g in StaticStuff.analysis_graphs])\n",
    "        for i, pattern in enumerate(StaticStuff.target_patterns):\n",
    "            pattern_match_score_data = tuple(abs(p - v) for p, v in zip(pattern, normalized_coupling_values) if p is not None)\n",
    "            match_score, support = pattern_match(normalized_coupling_values, pattern, support_values)\n",
    "            if match_score >= MIN_PATTERN_MATCH and support >= MIN_SUPPORT:\n",
    "                result[i].append((pattern_match_score_data, (a, b, normalized_coupling_values, support)))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BestResultsSet:\n",
    "    def __init__(self, dimension_count, result_keep_size):\n",
    "        self.dimension_count = dimension_count\n",
    "        self.result_keep_size = result_keep_size\n",
    "        self.data = []  # pair of ([coordinates per dimension], user-data)\n",
    "        self.total_amount = 0\n",
    "    \n",
    "    def add_all(self, new_data):\n",
    "        self.data += new_data\n",
    "        self.total_amount += len(new_data)\n",
    "        self.trim_maybe()\n",
    "        \n",
    "    def get_best(self, dim_weights):\n",
    "        def sort_key(datum):\n",
    "            return sum(datum[0][i] * weight for i, weight in enumerate(dim_weights))\n",
    "        self.data.sort(key=sort_key)\n",
    "        return self.data[:self.result_keep_size]\n",
    "    \n",
    "    def trim_maybe(self):\n",
    "        if len(self.data) > self.result_keep_size * 10 * self.dimension_count:\n",
    "            self.trim()\n",
    "    \n",
    "    def trim(self):\n",
    "        result_keep_tolerance = 2  # higher = keep more, but better chance at not accidentally removing important stuff\n",
    "        sampling_accuracy = 10  # higher = more runtime, but more acurately detecting required important data\n",
    "        # previous_size = len(self.data)\n",
    "        important_data = set()\n",
    "        prev_result_keep_size = self.result_keep_size\n",
    "        self.result_keep_size *= result_keep_tolerance\n",
    "        for dim_weight in generate_one_distributions(self.dimension_count, sampling_accuracy):\n",
    "            important_data.update(self.get_best(dim_weight))\n",
    "        self.result_keep_size = prev_result_keep_size\n",
    "        self.data = list(important_data)\n",
    "        # print(\"Trimming reduced from\", previous_size, \"to\", len(self.data), \"elements\")\n",
    "    \n",
    "    def export_to_csv(self, name):\n",
    "        \"\"\"only works for 2 dimensions!\"\"\"\n",
    "        with open(name + \".csv.txt\", \"w\") as f:\n",
    "            f.write(\"x,y\\n1,1\\n\" + \"\\n\".join(str(d[1][2][0])+\",\"+str(d[1][2][1]) for d in self.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHOW_RESULTS_SIZE = 20\n",
    "def analyze_disagreements(repo, views, target_patterns, node_filter_func = None, node_pair_filter_func = None):\n",
    "    \"\"\"\n",
    "    when views are [struct, evo, ling], the pattern [0, 1, None, \"comment\"] searches for nodes that are\n",
    "    strongly coupled evolutionary, loosely coupled structurally, and the language does not matter\n",
    "    \"\"\"\n",
    "    if len(views) <= 1:\n",
    "        return\n",
    "    if not all([len(p) >= len(views) for p in target_patterns]):\n",
    "        print(\"Patterns need at least one element per graph!\")\n",
    "        return\n",
    "    \n",
    "    \n",
    "    \n",
    "    analysis_graphs = list([MetricManager.get(repo, g) for g in views])\n",
    "    #for g in analysis_graphs:\n",
    "    #    g.propagate_down(2, 0.2)\n",
    "    analysis_graph_nodes = [g.get_node_set() for g in analysis_graphs]\n",
    "    all_nodes = list(set.intersection(*[nodes for nodes in analysis_graph_nodes if nodes is not None]))\n",
    "    all_nodes = [n for n in all_nodes if repo.get_tree().has_node(n)]\n",
    "    print(\"Total node count:\", len(all_nodes))\n",
    "    print(\"Methods:\", sum(repo.get_tree().find_node(path).get_type() == \"method\" for path in all_nodes))\n",
    "    print(\"constructors:\", sum(repo.get_tree().find_node(path).get_type() == \"constructor\" for path in all_nodes))\n",
    "    print(\"fields:\", sum(repo.get_tree().find_node(path).get_type() == \"field\" for path in all_nodes))\n",
    "    print(\"classes:\", sum(repo.get_tree().find_node(path).get_type() == \"class\" for path in all_nodes))\n",
    "    print(\"interfaces:\", sum(repo.get_tree().find_node(path).get_type() == \"interface\" for path in all_nodes))\n",
    "    print(\"enums:\", sum(repo.get_tree().find_node(path).get_type() == \"enum\" for path in all_nodes))\n",
    "    print(\"without type:\", sum(repo.get_tree().find_node(path).get_type() is None for path in all_nodes))\n",
    "    if node_filter_func is not None:\n",
    "        all_nodes = [node for node in all_nodes if node_filter_func(node)]\n",
    "    print(\"all filtered nodes:\", len(all_nodes))\n",
    "    print(\"logic/Background.java/Background/background\" in all_nodes)\n",
    "    print(\"logic/Background.java/Background/stars0\" in all_nodes)\n",
    "    \n",
    "    all_node_pairs = list(all_pairs(all_nodes))\n",
    "    if node_pair_filter_func is not None:\n",
    "        prev_len = len(all_node_pairs)\n",
    "        all_node_pairs = [pair for pair in all_node_pairs if node_pair_filter_func(pair[0], pair[1])]\n",
    "        print(\"Amount of node pairs to check:\", len(all_node_pairs), \"of\", prev_len, \"(\" + str(len(all_node_pairs)/prev_len*100) + \"%)\")\n",
    "        \n",
    "        \n",
    "    print(\"Going parallel...\")\n",
    "    pattern_results = [\n",
    "        BestResultsSet(sum(type(x)==int for x in p), SHOW_RESULTS_SIZE)\n",
    "        for p in target_patterns]\n",
    "    def handle_results(pattern_results_part):\n",
    "        for i, part in enumerate(pattern_results_part):\n",
    "            pattern_results[i].add_all(part)\n",
    "    StaticStuff.analysis_graphs = analysis_graphs\n",
    "    StaticStuff.target_patterns = target_patterns\n",
    "    print((\"logic/Background.java/Background/background\", \"logic/Background.java/Background/stars0\") in all_node_pairs)\n",
    "    print((\"logic/Background.java/Background/stars0\", \"logic/Background.java/Background/background\") in all_node_pairs)\n",
    "    map_parallel(\n",
    "        all_node_pairs,\n",
    "        analyze_pair, # partial(analyze_pair, analysis_graphs=analysis_graphs, target_patterns=target_patterns),\n",
    "        handle_results,\n",
    "        \"Analyzing edges\",\n",
    "        force_non_parallel=True\n",
    "    )\n",
    "    \n",
    "    print(\"Results:\")\n",
    "    for i, (pattern, results) in enumerate(zip(target_patterns, pattern_results)):\n",
    "        print(\"\\nPattern \" + str(i) + \" (\" + str(pattern) + \"):\")\n",
    "            \n",
    "        def nice_path(path):\n",
    "            ending = \".\" + repo.type_extension()\n",
    "            if ending in path:\n",
    "                return path[path.index(ending) + len(ending) + 1:]\n",
    "            return path\n",
    "        \n",
    "        def get_raw_i(i):\n",
    "            def getter(d):\n",
    "                return d[1][2][i]\n",
    "            return getter\n",
    "        def get_i(i):\n",
    "            def getter(d):\n",
    "                return d[0][i]\n",
    "            return getter\n",
    "        name_and_raw_getters = [(name, get_raw_i(i)) for i, name in enumerate(views) if pattern[i] is not None]\n",
    "        sort_val_getters = [get_i(i) for i in range(len([p for p in pattern if p is not None]))]\n",
    "        dimensions = [(name, get, get_raw) for (name, get_raw), get in zip(name_and_raw_getters, sort_val_getters)]\n",
    "        def make_show_data(dim):\n",
    "            def show_data(multi_sorted_results):\n",
    "                print(results.total_amount, \"raw results,\", len(multi_sorted_results), \"final results\")\n",
    "\n",
    "                display_data = multi_sorted_results[:SHOW_RESULTS_SIZE]\n",
    "                #for d in display_data:\n",
    "                #    print(d)\n",
    "                display_data = [\n",
    "                    [\"{:1.4f}\".format(raw_getter(datum)) for name, getter, raw_getter in dim] +\n",
    "                    [\"{:1.4f}\".format(datum[1][3])] +\n",
    "                    ['<a target=\"_blank\" href=\"' + repo.url_for(path) + '\" title=\"' + path + '\">' + nice_path(path) + '</a>' for path in datum[1][0:2]]\n",
    "                    for datum in display_data]\n",
    "                header = [name for name, *_ in dim] + [\"support\", \"method 1\", \"method 2\"]\n",
    "                show_html_table([header] + display_data, len(dim) + 3)\n",
    "            return show_data\n",
    "        #results.export_to_csv(\"full\")\n",
    "        results.trim()\n",
    "        #results.export_to_csv(\"trimmed\")\n",
    "        interactive_multi_sort(results.data, dimensions, make_show_data(dimensions)) \n",
    "        \n",
    "    \n",
    "    \n",
    "    # pdb.set_trace()\n",
    "    # TODO trim node set of nodes to those they have in common?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyPy3",
   "language": "python",
   "name": "pypy3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
