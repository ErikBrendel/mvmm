{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "%matplotlib inline\n",
    "%run LocalRepo.ipynb\n",
    "%run repos.ipynb\n",
    "%run parsing.ipynb\n",
    "%run metrics.ipynb\n",
    "from best_results_set import BestResultsSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pattern_match(coupling_values, pattern, support_values):\n",
    "    \"\"\"how good does this node-pair fit to the given pattern? Range: [0, 1]\"\"\"\n",
    "    error_sum = 0; values = 0; support = 1\n",
    "    for i, coupling_val in enumerate(coupling_values):\n",
    "        if pattern[i] is not None:\n",
    "            error = abs(pattern[i] - coupling_val)\n",
    "            error_sum += error * error\n",
    "            values += 1\n",
    "            support = min(support, support_values[i])\n",
    "    match_score = 1. - (error_sum / values)\n",
    "    return match_score, support\n",
    "\n",
    "\n",
    "# as seen in:\n",
    "# https://thelaziestprogrammer.com/python/a-multiprocessing-pool-pickle\n",
    "# https://thelaziestprogrammer.com/python/multiprocessing-pool-a-global-solution\n",
    "class StaticStuff:\n",
    "    analysis_graphs = None\n",
    "    target_patterns = None\n",
    "\n",
    "MIN_PATTERN_MATCH = 0  # how close the coupling values need to match the pattern to be a result\n",
    "MIN_SUPPORT = 0  # how much relative support a result needs to not be discarded\n",
    "def analyze_pair(pair): #, analysis_graphs, target_patterns):\n",
    "    # pdb.set_trace()\n",
    "    _a, _b = pair\n",
    "    if _a.startswith(_b) or _b.startswith(_a):  # ignore nodes that are in a parent-child relation\n",
    "        return None\n",
    "    # for each view: how much support do we have for this node pair (minimum of both node support values)\n",
    "    support_values = [min(supp_a, supp_b) for supp_a, supp_b in zip(*[\n",
    "        [g.get_normalized_support(node) for g in StaticStuff.analysis_graphs] for node in [_a, _b]\n",
    "    ])]\n",
    "    result = [[] for p in StaticStuff.target_patterns]\n",
    "    for a, b in [(_a, _b), (_b, _a)]:\n",
    "        normalized_coupling_values = tuple([g.get_normalized_coupling(a, b) for g in StaticStuff.analysis_graphs])\n",
    "        for i, pattern in enumerate(StaticStuff.target_patterns):\n",
    "            pattern_match_score_data = tuple(abs(p - v) for p, v in zip(pattern, normalized_coupling_values) if p is not None)\n",
    "            match_score, support = pattern_match(normalized_coupling_values, pattern, support_values)\n",
    "            if match_score >= MIN_PATTERN_MATCH and support >= MIN_SUPPORT:\n",
    "                result[i].append(((*pattern_match_score_data, -support), (a, b, (*normalized_coupling_values, support))))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHOW_RESULTS_SIZE = 50\n",
    "def analyze_disagreements(repo, views, target_patterns, node_filter_func = None, node_pair_filter_func = None):\n",
    "    \"\"\"\n",
    "    when views are [struct, evo, ling], the pattern [0, 1, None, \"comment\"] searches for nodes that are\n",
    "    strongly coupled evolutionary, loosely coupled structurally, and the language does not matter\n",
    "    \"\"\"\n",
    "    if len(views) < 1:\n",
    "        return\n",
    "    if not all([len(p) >= len(views) for p in target_patterns]):\n",
    "        print(\"Patterns need at least one element per graph!\")\n",
    "        return\n",
    "    \n",
    "    \n",
    "    \n",
    "    analysis_graphs = list([MetricManager.get(repo, g) for g in views])\n",
    "    #for g in analysis_graphs:\n",
    "    #    g.propagate_down(2, 0.2)\n",
    "    analysis_graph_nodes = [g.get_node_set() for g in analysis_graphs]\n",
    "    all_nodes = list(set.intersection(*[nodes for nodes in analysis_graph_nodes if nodes is not None]))\n",
    "    all_nodes = [n for n in all_nodes if repo.get_tree().has_node(n)]\n",
    "    \n",
    "    union_nodes = list(set.union(*[nodes for nodes in analysis_graph_nodes if nodes is not None]))\n",
    "    union_nodes = set([n for n in union_nodes if repo.get_tree().has_node(n)])\n",
    "    print(\"Intersection Nodes: \" + str(len(all_nodes)) + \", Union Nodes: \" + str(len(union_nodes)))\n",
    "    for view, graph in zip(views, analysis_graphs):\n",
    "        graph_nodes = graph.get_node_set()\n",
    "        if graph_nodes is None:\n",
    "            continue\n",
    "        graph_nodes = set([n for n in graph_nodes if repo.get_tree().has_node(n)])\n",
    "        in_view_not_intersection = list(graph_nodes.difference(set(all_nodes)))\n",
    "        in_union_not_view = list(union_nodes.difference(graph_nodes))\n",
    "        print(\"  View '\" + view + \"': \" + str(len(graph_nodes)) + \" Nodes in total\")\n",
    "        if len(in_view_not_intersection) > 0:\n",
    "            print(\"    In view but not intersection: \" + str(len(in_view_not_intersection)))\n",
    "            for path in in_view_not_intersection[:5]:\n",
    "                print(\"      \" + repo.url_for(path) + \" \" + path.split(\"/\")[-1])\n",
    "        if len(in_union_not_view) > 0:\n",
    "            print(\"    In union but not view: \" + str(len(in_union_not_view)))\n",
    "            for path in in_union_not_view[:5]:\n",
    "                print(\"      \" + repo.url_for(path) + \" \" + path.split(\"/\")[-1])\n",
    "    \n",
    "    \n",
    "    print(\"Total node count:\", len(all_nodes))\n",
    "    print(\"Methods:\", sum(repo.get_tree().find_node(path).get_type() == \"method\" for path in all_nodes))\n",
    "    print(\"constructors:\", sum(repo.get_tree().find_node(path).get_type() == \"constructor\" for path in all_nodes))\n",
    "    print(\"fields:\", sum(repo.get_tree().find_node(path).get_type() == \"field\" for path in all_nodes))\n",
    "    print(\"classes:\", sum(repo.get_tree().find_node(path).get_type() == \"class\" for path in all_nodes))\n",
    "    print(\"interfaces:\", sum(repo.get_tree().find_node(path).get_type() == \"interface\" for path in all_nodes))\n",
    "    print(\"enums:\", sum(repo.get_tree().find_node(path).get_type() == \"enum\" for path in all_nodes))\n",
    "    print(\"without type:\", sum(repo.get_tree().find_node(path).get_type() is None for path in all_nodes))\n",
    "    if node_filter_func is not None:\n",
    "        all_nodes = [node for node in all_nodes if node_filter_func(node)]\n",
    "    print(\"all filtered nodes:\", len(all_nodes))\n",
    "    \n",
    "    all_node_pairs = list(all_pairs(all_nodes))\n",
    "    if node_pair_filter_func is not None:\n",
    "        prev_len = len(all_node_pairs)\n",
    "        all_node_pairs = [pair for pair in all_node_pairs if node_pair_filter_func(pair[0], pair[1])]\n",
    "        if len(all_node_pairs) == 0:\n",
    "            print(\"NO NODES TO ANALYZE, ABORTING!\")\n",
    "            return\n",
    "        print(\"Amount of node pairs to check:\", len(all_node_pairs), \"of\", prev_len, \"(\" + str(len(all_node_pairs)/prev_len*100) + \"%)\")\n",
    "        \n",
    "    # all_node_pairs = all_node_pairs[:1000]\n",
    "        \n",
    "    print(\"Going parallel...\")\n",
    "    pattern_results = [\n",
    "        BestResultsSet(sum(type(x)==int for x in p) + 1, SHOW_RESULTS_SIZE)  # one dim for each graph that is used in the pattern + 1 for support\n",
    "        for p in target_patterns]\n",
    "    def handle_results(pattern_results_part):\n",
    "        for i, part in enumerate(pattern_results_part):\n",
    "            pattern_results[i].add_all(part)\n",
    "    StaticStuff.analysis_graphs = analysis_graphs\n",
    "    StaticStuff.target_patterns = target_patterns\n",
    "    map_parallel(\n",
    "        all_node_pairs,\n",
    "        analyze_pair, # partial(analyze_pair, analysis_graphs=analysis_graphs, target_patterns=target_patterns),\n",
    "        handle_results,\n",
    "        \"Analyzing edges\",\n",
    "        force_non_parallel=True\n",
    "    )\n",
    "    \n",
    "    print(\"Results:\")\n",
    "    for i, (pattern, results) in enumerate(zip(target_patterns, pattern_results)):\n",
    "        print(\"\\nPattern \" + str(i) + \" (\" + str(pattern) + \"):\")\n",
    "            \n",
    "        def nice_path(path):\n",
    "            ending = \".\" + repo.type_extension()\n",
    "            if ending in path:\n",
    "                return path[path.index(ending) + len(ending) + 1:]\n",
    "            return path\n",
    "        \n",
    "        def get_raw_i(i):\n",
    "            def getter(d):\n",
    "                return d[1][2][i]\n",
    "            return getter\n",
    "        def get_i(i):\n",
    "            def getter(d):\n",
    "                return d[0][i]\n",
    "            return getter\n",
    "        name_and_raw_getters = [(name, get_raw_i(i)) for i, name in enumerate(views) if pattern[i] is not None] + [(\"support\", get_raw_i(-1))]\n",
    "        sort_val_getters = [get_i(i) for i in range(len([p for p in pattern if p is not None]))] + [(get_i(-1))]\n",
    "        dimensions = [(name, get, get_raw) for (name, get_raw), get in zip(name_and_raw_getters, sort_val_getters)]\n",
    "        def make_show_data(dim):\n",
    "            def show_data(multi_sorted_results):\n",
    "                print(results.total_amount, \"raw results,\", len(multi_sorted_results), \"final results\")\n",
    "\n",
    "                display_data = multi_sorted_results[:SHOW_RESULTS_SIZE]\n",
    "                #for d in display_data:\n",
    "                #    print(d)\n",
    "                display_data = [\n",
    "                    [\"{:1.4f}\".format(raw_getter(datum)) for name, getter, raw_getter in dim] +\n",
    "                    ['<a target=\"_blank\" href=\"' + repo.url_for(path) + '\" title=\"' + path + '\">' + nice_path(path) + '</a>' for path in datum[1][0:2]]\n",
    "                    for datum in display_data]\n",
    "                header = [name for name, *_ in dim] + [\"support\", \"method 1\", \"method 2\"]\n",
    "                show_html_table([header] + display_data, len(dim) + 2)\n",
    "            return show_data\n",
    "        # results.trim()\n",
    "        interactive_multi_sort(results.data, dimensions, make_show_data(dimensions)) \n",
    "        \n",
    "    \n",
    "    \n",
    "    # pdb.set_trace()\n",
    "    # TODO trim node set of nodes to those they have in common?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyPy3",
   "language": "python",
   "name": "pypy3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
