{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "%matplotlib inline\n",
    "%run LocalRepo.ipynb\n",
    "%run repos.ipynb\n",
    "%run parsing.ipynb\n",
    "%run metrics.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnalysisGraph:\n",
    "    def __init__(self, g):\n",
    "        self.g = g\n",
    "        self.children = {}\n",
    "        for n in self.g.g.nodes:\n",
    "            while n is not None:\n",
    "                p = self.get_parent(n)\n",
    "                self.children.setdefault(p, set()).add(n)\n",
    "                n = p\n",
    "        self.total_relative_coupling_cache = {}\n",
    "        self.median_maximum_support_cache = None\n",
    "        \n",
    "    def get_children(self, node):\n",
    "        if node in self.children:\n",
    "            return self.children[node]\n",
    "        else:\n",
    "            return []\n",
    "        \n",
    "    def get_parent(self, node):\n",
    "        if len(node) <= 1:\n",
    "            return None\n",
    "        return \"/\".join(node.split(\"/\")[:-1])\n",
    "    \n",
    "    def get_directly_coupled(self, node):\n",
    "        if node in self.g.g:\n",
    "            return [n for n in self.g.g[node]]\n",
    "        else:\n",
    "            return []\n",
    "    \n",
    "    def get_siblings(self, node):\n",
    "        \"\"\"Return all the other children of this.parent (excluding this)\"\"\"\n",
    "        parent = self.get_parent(node)\n",
    "        if parent is None:\n",
    "            return []\n",
    "        return [c for c in self.get_children(parent) if c != node]\n",
    "    \n",
    "    def get_coupling_candidates(self, node, add_predecessors = False):\n",
    "        \"\"\"Return all the nodes with which the given one could have a non-zero relative coupling.\n",
    "         * := The direct coupling nodes of given+descendants, and all their predecessors\"\"\"\n",
    "        this_and_descendants = self.get_self_and_descendants(node)\n",
    "        \n",
    "        direct_coupling_candidates = []\n",
    "        for n in this_and_descendants:\n",
    "            for n2 in self.get_directly_coupled(n):\n",
    "                direct_coupling_candidates.append(n2)\n",
    "        \n",
    "        result = set()\n",
    "        result.add(\"\")  # root node, added to stop the predecessor iteration\n",
    "        for other in direct_coupling_candidates:\n",
    "            while result.add(other): # while not present yet\n",
    "                if not add_predecessors:\n",
    "                    break\n",
    "                other = self.get_parent(other)\n",
    "        result.remove(\"\")  # root node - removed, since not very interesting\n",
    "        return result\n",
    "    \n",
    "        \n",
    "    def get_self_and_descendants(self, node):\n",
    "        \"\"\"return the given node and all its descendants as a list\"\"\"\n",
    "        result = []\n",
    "        self.get_self_and_descendants_rec(node, result)\n",
    "        return result\n",
    "    \n",
    "    def get_self_and_descendants_rec(self, node, result):\n",
    "        \"\"\"add the given node and all its descendants into the provided list\"\"\"\n",
    "        result.append(node)\n",
    "        for child in self.get_children(node):\n",
    "            self.get_self_and_descendants_rec(child, result)\n",
    "            \n",
    "    \n",
    "    def get_direct_coupling(self, a, b):\n",
    "        \"\"\"direct coupling between a and b\"\"\"\n",
    "        return self.g.get(a, b)\n",
    "    \n",
    "    def get_direct_multi_coupling(self, a, others):\n",
    "        \"\"\"sum of direct coupling between a and all b\"\"\"\n",
    "        return sum([self.get_direct_coupling(a, b) for b in others])\n",
    "    \n",
    "    def get_relative_coupling(self, a, b):\n",
    "        \"\"\"sum of direct coupling between a+descendants and b+descendants\"\"\"\n",
    "        others = self.get_self_and_descendants(b)\n",
    "        return self.get_relative_multi_direct_coupling(a, others)\n",
    "    \n",
    "    def get_relative_multi_coupling(self, a, others):\n",
    "        \"\"\"sum of direct coupling between a+descendants and others+descendants\"\"\"\n",
    "        direct_others = []\n",
    "        for other in others:\n",
    "            self.get_self_and_descendants_rec(other, direct_others)\n",
    "        return self.get_relative_multi_direct_coupling(a, direct_others)\n",
    "    \n",
    "    def get_relative_multi_direct_coupling(self, a, others):\n",
    "        \"\"\"sum of direct coupling between a+descendants and others\"\"\"\n",
    "        if len(others) == 0:\n",
    "            return 0\n",
    "        result = self.get_direct_multi_coupling(a, others)\n",
    "        for child in self.get_children(a):\n",
    "            result += self.get_relative_multi_direct_coupling(child, others)\n",
    "        return result\n",
    "    \n",
    "    def get_total_relative_coupling(self, a):\n",
    "        \"\"\"the sum of direct couplings that a has, cached\"\"\"\n",
    "        if a in self.total_relative_coupling_cache:\n",
    "            return self.total_relative_coupling_cache[a]\n",
    "        \n",
    "        a_candidates = self.get_coupling_candidates(a, add_predecessors = False)\n",
    "        total_coupling = self.get_relative_multi_direct_coupling(a, a_candidates)\n",
    "        self.total_relative_coupling_cache[a] = total_coupling\n",
    "        return total_coupling\n",
    "    \n",
    "    def get_normalized_coupling(self, a, b):\n",
    "        \"\"\"relative coupling between a and b, normalized by the sum of couplings that a has, in range [0, 1]\"\"\"\n",
    "        if a not in self.g.g or b not in self.g.g:\n",
    "            return 0\n",
    "        target_coupling = self.get_relative_coupling(a, b)\n",
    "        if target_coupling == 0:\n",
    "            return 0\n",
    "        total_coupling = self.get_total_relative_coupling(a)\n",
    "        return target_coupling / total_coupling\n",
    "    \n",
    "    \n",
    "    def get_normalized_support(self, node):\n",
    "        \"\"\"\n",
    "        on a scale of [0, 1], how much support do we have for coupling values with that node?\n",
    "        This should depend on how much data (including children) we have for this node, relative to how much data is normal in this graph.\n",
    "        It should also be outlier-stable, so that having median-much data maybe results in a support score of 0.5?\n",
    "        \"\"\"\n",
    "        abs_supp = self.get_absolute_support(node)\n",
    "        median, maximum = self.get_absolute_support_median_and_max()\n",
    "        if abs_supp <= median:\n",
    "            return 0.5 * abs_supp / median\n",
    "        else:\n",
    "            return 0.5 + (0.5 * (abs_supp - median) / (maximum - median))\n",
    "    \n",
    "    def get_absolute_support(self, node):\n",
    "        result = self.get_absolute_self_support(node)\n",
    "        for child in self.get_children(node):\n",
    "            result += self.get_absolute_support(child)\n",
    "        return result\n",
    "        \n",
    "    def get_absolute_self_support(self, node):\n",
    "        return self.g.get_support(node)\n",
    "    \n",
    "    def get_absolute_support_median_and_max(self):\n",
    "        if self.median_maximum_support_cache is None:\n",
    "            supports = list([self.get_absolute_support(node) for node in self.g.g.nodes])\n",
    "            median = np.median(supports)\n",
    "            maximum = max(supports)\n",
    "            self.median_maximum_support_cache = (median, maximum)\n",
    "        return self.median_maximum_support_cache\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_disagreements(repo, coupling_graphs, target_patterns):\n",
    "    \"\"\"\n",
    "    when views are [struct, evo, ling], the pattern [0, 1, None, \"comment\"] searches for nodes that are\n",
    "    strongly coupled evolutionary, loosely coupled structurally, and the language does not matter\n",
    "    \"\"\"\n",
    "    if len(coupling_graphs) <= 1:\n",
    "        return\n",
    "    if not all([len(p) >= len(coupling_graphs) for p in target_patterns]):\n",
    "        print(\"Patterns need at least one element per graph!\")\n",
    "        return\n",
    "    \n",
    "    MIN_PATTERN_MATCH = 0.66  # how close the coupling values need to match the pattern to be a result\n",
    "    MIN_SUPPORT = 0.1  # how much relative support a result needs to not be discarded\n",
    "    \n",
    "    def pattern_match(coupling_values, pattern, support_values):\n",
    "        \"\"\"how good does this node-pair fit to the given pattern? Range: [0, 1]\"\"\"\n",
    "        error_sum = 0; values = 0; support = 1\n",
    "        for i, coupling_val in enumerate(coupling_values):\n",
    "            if pattern[i] is not None:\n",
    "                error = abs(pattern[i] - coupling_val)\n",
    "                error_sum += error * error\n",
    "                values += 1\n",
    "                support = min(support, support_values[i])\n",
    "        match_score = 1. - (error_sum / values)\n",
    "        return match_score, support\n",
    "    \n",
    "    analysis_graphs = list([AnalysisGraph(g) for g in coupling_graphs])\n",
    "    all_nodes = list(set.intersection(*[set(g.g.nodes) for g in coupling_graphs]))\n",
    "    all_nodes = [n for n in all_nodes if repo.get_tree().has_node(n)]\n",
    "    print(\"Total node count:\", len(all_nodes))\n",
    "    # print(\"Intersection node count:\", len(list(set.intersection(*[set(g.g.nodes) for g in coupling_graphs]))))\n",
    "    \n",
    "    pattern_results = [[] for p in target_patterns]\n",
    "    for _a, _b in log_progress(list(all_pairs(all_nodes)), desc=\"Analyzing edges\", smoothing=0.1):\n",
    "        if _a.startswith(_b) or _b.startswith(_a):  # ignore nodes that are in a parent-child relation\n",
    "            continue\n",
    "        # for each view: how much support do we have for this node pair (minimum of both node support values)\n",
    "        support_values = [min(supp_a, supp_b) for supp_a, supp_b in zip(*[\n",
    "            [g.get_normalized_support(node) for g in analysis_graphs] for node in [_a, _b]\n",
    "        ])]\n",
    "        for a, b in [(_a, _b), (_b, _a)]:\n",
    "            normalized_coupling_values = list([g.get_normalized_coupling(a, b) for g in analysis_graphs])\n",
    "            for i, pattern in enumerate(target_patterns):\n",
    "                match_score, support = pattern_match(normalized_coupling_values, pattern, support_values)\n",
    "                if match_score >= MIN_PATTERN_MATCH and support >= MIN_SUPPORT:\n",
    "                    pattern_results[i].append((a, b, match_score * support))\n",
    "    \n",
    "    print(\"Results:\")\n",
    "    for i, (pattern, results) in enumerate(zip(target_patterns, pattern_results)):\n",
    "        print(\"\\nPattern \" + str(i) + \" (\" + str(pattern) + \"):\")\n",
    "        sorted_results = sorted(results, key = lambda e: -e[2])\n",
    "        print(\"  Amount of disagreements:\", len(sorted_results), \"which is\", str(round(100*len(sorted_results)/(len(all_nodes)*len(all_nodes)), 2))+\"%\", \"of all edges\")\n",
    "\n",
    "\n",
    "        values = [v for a, b, v in sorted_results]\n",
    "        plt.hist(values, \"auto\", facecolor='g', alpha=0.75)\n",
    "        plt.axvline(np.array(values).mean(), color='k', linestyle='dashed', linewidth=1)\n",
    "        # plt.xscale(\"log\")\n",
    "        # plt.yscale(\"log\")\n",
    "        plt.xlabel('Pattern match')\n",
    "        plt.ylabel('Amount of results')\n",
    "        plt.title('Histogram of pattern matching strengths')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "        strong_matches = [(a, b, v) for a, b, v in sorted_results if v <= 1]\n",
    "        print(\"  Strong nontrivial disagreements:\", len(strong_matches))\n",
    "        for a, b, v in  strong_matches[:10]:\n",
    "            print(\"  \", a, \"<>\", b, \" - \", v)\n",
    "    \n",
    "    \n",
    "    # pdb.set_trace()\n",
    "    # TODO trim node set of nodes to those they have in common?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    r = LocalRepo(\"ErikBrendel/LudumDare\")\n",
    "    analyze_disagreements([MetricManager.get(r, view) for view in [\"structural\", \"evolutionary\"]], [[0, 1], [None, 1], [1, None]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
